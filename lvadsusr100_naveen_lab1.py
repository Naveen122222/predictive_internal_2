# -*- coding: utf-8 -*-
"""LVADSUSR100_Naveen_Lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jWUu5cIDZGIM7_8e47AicA-6loxkhjfz
"""

import pandas as pd
data=pd.read_csv("/content/winequality-red.csv")
df=pd.DataFrame(data)
df.head()

#finding null values

df.isnull().sum()

#to fill the null values we use
df = df.fillna(method='ffill')
#here we use forwordfill method to fill the all NaN value

#removing outliers from the data set
import matplotlib.pyplot as plt
plt.boxplot(df['fixed acidity'])
plt.show()

#here we have outliers

df=df[df['fixed acidity']<12]

plt.boxplot(df['free sulfur dioxide'])
plt.show()

df=df[df['free sulfur dioxide']<40]

plt.boxplot(df['total sulfur dioxide'])
plt.show()

df=df[df['total sulfur dioxide']<=104]

lis=[]
for i in df['quality']:
  if i<=6:
    lis.append(0)
  elif i>6 and i<=8:
    lis.append(1)
print(lis)

df['Target_Quality']=lis

#here we are Droping duplicate rows from the dataset
df.drop_duplicates(inplace=True)

X=df.drop(['Target_Quality','quality'],axis=1)
y=df['Target_Quality']

from sklearn.model_selection import train_test_split


X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)

from sklearn.neighbors import KNeighborsClassifier
KNC_classifier = KNeighborsClassifier()
print("KNeighborsClassifier")

## Model Training
KNC_classifier.fit(X_train,y_train)

## Model Testing
KNC_predictions=KNC_classifier.predict(X_test)

from sklearn.metrics import *

print("Accuracy : ",accuracy_score(y_test,KNC_predictions),'\n')

print("Precision : ",precision_score(y_test,KNC_predictions),'\n')

print("Recall : ",recall_score(y_test,KNC_predictions),'\n')

print("F1- Score : ",f1_score(y_test,KNC_predictions),'\n')